[
    {
        "name": "Diabetes",
        "latest_version": null,
        "description": "# Diabetes Linear Regression Model Documentation\n\n## Overview\n\nThis document provides an overview of the linear regression model developed for predicting diabetes progression using the diabetes dataset. The model is built using scikit-learn and is auto-logged using MLflow, a platform for managing the machine learning lifecycle.\n\n## Dataset\n\nThe model is trained on the [diabetes dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset) from scikit-learn. This dataset consists of ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements for 442 diabetes patients. The target variable is a quantitative measure of disease progression one year after baseline.\n\n## Model Details\n\n### Model Type\n\nThe diabetes linear regression model is a supervised machine learning model that uses linear regression to establish a relationship between a single feature (blood serum measurement) and the target variable (diabetes progression).\n\n### Model Training\n\nThe model is trained using scikit-learn's `LinearRegression` class. The training data is split into training and testing sets, where 20% of the data is used for testing. The selected feature for training is the third blood serum measurement (diabetes_X[:, np.newaxis, 2]).\n\n### Model Evaluation\n\nThe model's performance is evaluated using the following metrics:\n- Mean Squared Error (MSE): The mean squared difference between the actual and predicted values of diabetes progression on the test set.\n- Coefficient of Determination (R-squared): Also known as the coefficient of determination, this metric measures the proportion of the variance in the target variable that is predictable from the feature used by the model.\n\n### Model Autologging\n\nMLflow's auto-logging feature is enabled for this model using `mlflow.sklearn.autolog()`. This allows the model's hyperparameters, metrics, and artifacts to be automatically logged and stored in the designated MLflow tracking server.\n\n## Results\n\nAfter training the model and evaluating its performance on the test set, the following results were obtained:\n\n- Coefficients: The coefficients of the linear regression model represent the change in the predicted diabetes progression for a one-unit change in the selected feature (third blood serum measurement).\n- Mean Squared Error: The model's mean squared error on the test set is presented as a quantitative measure of its predictive accuracy.\n- Coefficient of Determination: The R-squared value indicates the proportion of the variance in diabetes progression that is explained by the linear relationship with the selected feature.\n\n## Model Usage\n\nOnce the model is trained and logged, it can be easily deployed and integrated into other applications or services for diabetes progression prediction.\n\n### Model Dependencies\n\nTo use this model, you'll need the following dependencies:\n- Python (>= 3.6)\n- scikit-learn (>= 0.24.2)\n- mlflow (>= 1.18.0)\n- numpy (>= 1.19.5)\n\n### Loading the Model\n\nThe trained model can be loaded using the MLflow API and used to make predictions.\n\n```python\nimport mlflow.sklearn\n\n# Load the trained model\nmodel = mlflow.sklearn.load_model(\"Diabetes\")\n\n# Use the model to make predictions\npredictions = model.predict(diabetes_X_test)\n```",
        "tags": {
            "author": "John Doe",
            "created_at": "2023-08-04",
            "framework": "scikit-learn",
            "version": "1.0"
        }
    },
    {
        "name": "Forecasting Wind Power",
        "latest_version": "9",
        "description": "# Forecasting Wind Power Model Documentation\n\n## Overview\n\nThis document provides documentation for the \"Forecasting Wind Power\" model. The model is built to predict wind power using the RandomForestRegressor algorithm and is trained on the California housing dataset.\n\n## Model Details\n\nThe \"Forecasting Wind Power\" model is developed using the `RandomForestRegressor` algorithm from scikit-learn. It aims to predict wind power based on various input features from the California housing dataset.\n\n## Dataset\n\nThe model is trained on the California housing dataset obtained from scikit-learn's `fetch_california_housing` function. The dataset contains various features, including average occupancy, average income, and geographical coordinates, used to predict the target variable, wind power.\n\n## Model Training\n\nThe model is trained using the RandomForestRegressor with hyperparameters:\n- `n_estimators`: The number of trees in the forest.\n- `max_depth`: The maximum depth of the tree.\n- `max_features`: The number of features to consider when looking for the best split.\n\nThe training dataset is split into 80% training and 20% testing sets. The input features are scaled using `StandardScaler` before training.\n\n## Hyperparameter Tuning\n\nHyperparameter tuning is performed using the Hyperopt library. A search space is defined for `max_depth`, `n_estimators`, and `max_features`. The `fmin` function from Hyperopt's `tpe` algorithm is used to search for the optimal hyperparameters based on the mean squared error (MSE) loss.\n\n## Model Evaluation\n\nThe model's performance is evaluated based on the mean squared error (MSE) between the actual wind power values and the predicted values on the test dataset.\n\n## Model Versioning\n\nThe best model with the tuned hyperparameters is registered and versioned using MLflow. The registered model is given the name \"Forecasting Wind Power,\" and the best model version is saved.\n\n## Predictions\n\nThe model can be used to make predictions on new data. To do so, load the best model version using the `mlflow.sklearn.load_model` function, and then provide new data to obtain the predicted wind power values.\n\n## Dependencies\n\nThe following libraries and versions are required to run this model:\n- mlflow (>= 1.20.2)\n- scikit-learn (>= 0.24.2)\n- pandas (>= 1.3.1)\n- matplotlib (>= 3.4.2)\n- hyperopt (>= 0.2.5)\n\nPlease ensure you have these dependencies installed before running the model.\n\n\nThe model's performance is evaluated based on the mean squared error (MSE) between the actual wind power values and the predicted values on the test dataset.\n\n## Hyperparameter Tuning\n\nHyperparameter tuning is performed using the Hyperopt library to find the best combination of hyperparameters for the RandomForestRegressor.\n\n## Conclusion\n\nThe \"Forecasting Wind Power\" model is a RandomForestRegressor-based model trained on the California housing dataset. By tuning the hyperparameters using Hyperopt, the model's performance is optimized to predict wind power accurately. The model can be easily versioned, managed, and used for making predictions on new data using MLflow.\n",
        "tags": {
            "algorithm": "RandomForestRegressor",
            "author": "John Doe",
            "created_at": "2023-08-04",
            "framework": "scikit-learn",
            "max_depth": "6",
            "max_features": "3",
            "n_estimators": "100",
            "problem_type": "Regression"
        }
    },
    {
        "name": "Iris",
        "latest_version": "3",
        "description": "# Iris Setosa and Versicolor Classification Model\n\n## Overview\n\nThis document provides documentation for the \"Iris Setosa and Versicolor Classification\" model. The model is built to classify Iris flowers into two classes, Setosa and Versicolor, using the Support Vector Machine (SVM) algorithm. It is trained on the Iris dataset, containing petal length and petal width features.\n\n## Dataset\n\nThe model is trained on the famous Iris dataset from scikit-learn. The dataset contains samples of three different Iris flower species: Setosa, Versicolor, and Virginica. For this model, we focus on classifying Iris flowers into Setosa and Versicolor classes. The dataset consists of petal length and petal width features for each sample.\n\n## Model Details\n\nThe \"Iris Setosa and Versicolor Classification\" model is developed using the `SVC` (Support Vector Classification) algorithm from scikit-learn with a linear kernel. The SVM is a powerful classification technique that seeks to find the best decision boundary that separates the classes.\n\n## Model Training\n\nThe SVM classifier is trained using the petal length and petal width features of the Iris flowers. We perform a binary classification by considering only two classes, Setosa and Versicolor (ignoring Virginica). The `C` hyperparameter is set to 10000.0 to enforce hard-margin classification, allowing minimal margin violations in the training data.\n\n## Model Evaluation\n\nTo evaluate the model's performance, we use standard metrics like accuracy, precision, recall, and F1-score. Since the dataset contains only two classes, confusion matrix metrics are applicable.\n\n## Model Autologging\n\nMLflow's autologging feature is enabled for this model using `mlflow.sklearn.autolog()`. This ensures that all relevant model parameters, metrics, and artifacts are automatically logged and tracked in the designated MLflow tracking server.\n\n## Conclusion\n\nThe \"Iris Setosa and Versicolor Classification\" model demonstrates its ability to accurately classify Iris flowers into Setosa and Versicolor classes based on petal length and petal width features. By leveraging the power of Support Vector Machines, the model achieves a robust decision boundary to differentiate between the two classes. The model can be used for further insights or integrated into larger applications for Iris flower classification tasks.\n",
        "tags": {
            "C": "10000.0",
            "algorithm": "SupportVectorMachine",
            "author": "Jane Smith",
            "created_at": "2023-09-15",
            "framework": "scikit-learn",
            "kernel": "linear",
            "problem_type": "BinaryClassification"
        }
    }
]